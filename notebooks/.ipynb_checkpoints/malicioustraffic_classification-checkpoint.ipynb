{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00827594-ea9b-463b-a2e1-ccde96b60dd8",
   "metadata": {},
   "source": [
    "## Malicious Traffic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334572a6",
   "metadata": {},
   "source": [
    "### Setting up our Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a2dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import imblearn\n",
    "import matplotlib.pyplot as  plt\n",
    "import xgboost as xgb\n",
    "\n",
    "#Ignore Warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b3122",
   "metadata": {},
   "source": [
    "### We still need to label all of our columns and configure settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b474f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "#Load Data\n",
    "df1=pd.read_csv(\"..//data/MachineLearningCVE/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")#,nrows = 50000\n",
    "df2=pd.read_csv(\"..//data/MachineLearningCVE/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "df3=pd.read_csv(\"..//data/MachineLearningCVE/Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "df4=pd.read_csv(\"..//data/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "df5=pd.read_csv(\"../data/MachineLearningCVE/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "df6=pd.read_csv(\"..//data/MachineLearningCVE/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "df7=pd.read_csv(\"..//data/MachineLearningCVE/Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "df8=pd.read_csv(\"..//data/MachineLearningCVE/Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "\n",
    "#Now we need to merge them all into one dataframe\n",
    "\n",
    "df = pd.concat([df1,df2])\n",
    "del df1,df2\n",
    "df = pd.concat([df,df3])\n",
    "del df3\n",
    "df = pd.concat([df,df4])\n",
    "del df4\n",
    "df = pd.concat([df,df5])\n",
    "del df5\n",
    "df = pd.concat([df,df6])\n",
    "del df6\n",
    "df = pd.concat([df,df7])\n",
    "del df7\n",
    "df = pd.concat([df,df8])\n",
    "del df8\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2a19a",
   "metadata": {},
   "source": [
    "#### Now we have to remove all invalid entries such as NaN, Infinity, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d290e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df = df[df[i] != \"Infinity\"]\n",
    "    df = df[df[i] != np.nan]\n",
    "    df = df[df[i] != \",,\"]\n",
    "df[['Flow Bytes/s', ' Flow Packets/s']] = df[['Flow Bytes/s', ' Flow Packets/s']].apply(pd.to_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c905e97",
   "metadata": {},
   "source": [
    "### First let's look at some data, if it's bad we drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3596846e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Bwd PSH Flags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Bwd URG Flags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFwd Avg Bytes/Bulk\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df[' Bwd PSH Flags'].value_counts())\n",
    "print(df[' Bwd URG Flags'].value_counts())\n",
    "print(df['Fwd Avg Bytes/Bulk'].value_counts())\n",
    "print(df[' Fwd Avg Packets/Bulk'].value_counts())\n",
    "print(df[' Fwd Avg Bulk Rate'].value_counts())\n",
    "print(df[' Bwd Avg Bytes/Bulk'].value_counts())\n",
    "print(df[' Bwd Avg Packets/Bulk'].value_counts())\n",
    "print(df['Bwd Avg Bulk Rate'].value_counts())\n",
    "    \n",
    "#Data preprocesing\n",
    "df.drop([' Bwd PSH Flags'], axis=1, inplace=True)\n",
    "df.drop([' Bwd URG Flags'], axis=1, inplace=True)\n",
    "df.drop(['Fwd Avg Bytes/Bulk'], axis=1, inplace=True)\n",
    "df.drop([' Fwd Avg Packets/Bulk'], axis=1, inplace=True)\n",
    "df.drop([' Fwd Avg Bulk Rate'], axis=1, inplace=True)\n",
    "df.drop([' Bwd Avg Bytes/Bulk'], axis=1, inplace=True)\n",
    "df.drop([' Bwd Avg Packets/Bulk'], axis=1, inplace=True)\n",
    "df.drop(['Bwd Avg Bulk Rate'], axis=1, inplace=True)\n",
    "\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e2d2e",
   "metadata": {},
   "source": [
    "### Split dataset on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60898c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test=train_test_split(df,test_size=0.3, random_state=10)\n",
    "\n",
    "#Exploratory Analysis\n",
    "# Descriptive statistics\n",
    "train.describe()\n",
    "test.describe()\n",
    "\n",
    "# Packet Attack Distribution\n",
    "train[' Label'].value_counts()\n",
    "test[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda861e",
   "metadata": {},
   "source": [
    "### Scaling numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef7ad7",
   "metadata": {},
   "source": [
    "### creating one hot encoder object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "trainDep = train[' Label'].values.reshape(-1,1)\n",
    "trainDep = onehotencoder.fit_transform(trainDep).toarray()\n",
    "testDep = test[' Label'].values.reshape(-1,1)\n",
    "testDep = onehotencoder.fit_transform(testDep).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10598aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=sc_traindf\n",
    "train_y=trainDep[:,0]\n",
    "\n",
    "test_X=sc_testdf\n",
    "test_y=testDep[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70d275",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(train_X, train_y);\n",
    "\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_X.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "importances.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62989de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=20)\n",
    "rfe = rfe.fit(train_X, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_X.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features\n",
    "\n",
    "a = [i[0] for i in feature_map]\n",
    "train_X = train_X.iloc[:,a]\n",
    "test_X = test_X.iloc[:,a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Partition\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_X,train_y,train_size=0.70, random_state=2)\n",
    "\n",
    "#Fitting Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train KNeighborsClassifier Model\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(X_train, Y_train); \n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(n_jobs=-1, random_state=0)\n",
    "LGR_Classifier.fit(X_train, Y_train);\n",
    "\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Train Decision Tree Model\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "DTC_Classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ffd12d",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
    "models.append(('LogisticRegression', LGR_Classifier))\n",
    "\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38bc71",
   "metadata": {},
   "source": [
    "### Validate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea31840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING FOR TEST DATA\n",
    "pred_knn = KNN_Classifier.predict(test_X)\n",
    "pred_NB = BNB_Classifier.predict(test_X)\n",
    "pred_log = LGR_Classifier.predict(test_X)\n",
    "pred_dt = DTC_Classifier.predict(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
